---
title: CLadder
date: 2023-09-21
repo: causalNLP/cladder
arxiv: 2312.04350
# cover: https://images.unsplash.com/photo-1518810765707-4f7d5d811ce0?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1440&q=80
cover: https://images.unsplash.com/photo-1572814895138-9a1501883636?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1440&q=80
emoji: ü§π
description: A benchmark for formal causal reasoning in LLMs
level: published
status: NeurIPS 2023
---

> [CLadder: Assessing Causal Reasoning in Language Models](https://openreview.net/forum?id=hdZeYGNCTtN)
> 
> **Zhijing Jin**, **Yuen Chen**, **Felix Leeb**, **Luigi Gresele**, Ojasv Kamal, Zhiheng LYU, Kevin Blin, Fernando Gonzalez Adauto, Max Kleiman-Weiner, Mrinmaya Sachan, Bernhard Sch√∂lkopf

Recent developments in large language models (LLMs) have led to a surge of interest in the capabilities of these models. However, it is still unclear how well these models can perform causal reasoning, a key aspect of intelligence. Here, I worked with several colleagues to develop a benchmark to introduce a novel task we call "causal inference in natural language."

My contribution included designing and developing the dataset generation including simulating causal models and a rich verbalization of the questions, answers, and step-by-step solutions.

This paper was published in the main proceedings of [NeurIPS 2023](https://openreview.net/forum?id=e2wtjx0Yqu).

